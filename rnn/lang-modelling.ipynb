{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the text:  1130711\n",
      "Total number of unique characters in the text:  85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# READING AND PREPROCESISNGT THE TEXT FILE\n",
    "with open('1268-0.txt', 'r',encoding=\"utf8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "start_indx=text.find(\"THE MYSTERIOUS ISLAND\")\n",
    "end_indx=text.find(\"End of the Project Gutenberg EBook of The Mysterious Island, by Jules Verne\")\n",
    "\n",
    "text=text[start_indx:end_indx]\n",
    "char_set=set(text)\n",
    "\n",
    "print(\"Total number of characters in the text: \",len(text))\n",
    "print(\"Total number of unique characters in the text: \",len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoded shape :  (1130711,)\n",
      "The encoded text is :  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1 37 47 40 29 42 32  1 10 10\n",
      " 10  0  0  0  0  0 48 36 33  1 41 53 47 48 33 46 37 43 49 47  1 37 47 40\n",
      " 29 42 32  0  0 56 79  1 38 75 66 59 73  1 50 59 72 68 59  0  0 16 23 22\n",
      " 19  0  0  0  0  0 44 29 46 48  1 16 12 12 32 46 43 44 44 33 32  1 34 46\n",
      " 43 41  1 48]\n",
      "The decoded text is :  THE MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS ISLAND\n",
      "\n",
      "by Jules Verne\n",
      "\n",
      "1874\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PART 1--DROPPED FROM T\n"
     ]
    }
   ],
   "source": [
    "chars_sorted =sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text],dtype=np.int32)\n",
    "print (\"The encoded shape : \",text_encoded.shape)\n",
    "print(\"The encoded text is : \",text_encoded[:100])   \n",
    "print(\"The decoded text is : \",\"\".join(char_array[text_encoded[:100]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:  0\n",
      "Input:  tensor([48, 36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40,\n",
      "        29, 42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53,\n",
      "        47, 48, 33, 46])\n",
      "Target:  tensor([36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29,\n",
      "        42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47,\n",
      "        48, 33, 46, 37])\n",
      "Input decoded:  THE MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTER\n",
      "Target decoded:  HE MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERI\n",
      "Sequence:  1\n",
      "Input:  tensor([36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29,\n",
      "        42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47,\n",
      "        48, 33, 46, 37])\n",
      "Target:  tensor([33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42,\n",
      "        32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48,\n",
      "        33, 46, 37, 43])\n",
      "Input decoded:  HE MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERI\n",
      "Target decoded:  E MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIO\n",
      "Sequence:  2\n",
      "Input:  tensor([33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42,\n",
      "        32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48,\n",
      "        33, 46, 37, 43])\n",
      "Target:  tensor([ 1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,\n",
      "         1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33,\n",
      "        46, 37, 43, 49])\n",
      "Input decoded:  E MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIO\n",
      "Target decoded:   MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOU\n",
      "Sequence:  3\n",
      "Input:  tensor([ 1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,\n",
      "         1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33,\n",
      "        46, 37, 43, 49])\n",
      "Target:  tensor([41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,  1,\n",
      "        10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33, 46,\n",
      "        37, 43, 49, 47])\n",
      "Input decoded:   MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOU\n",
      "Target decoded:  MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS\n",
      "Sequence:  4\n",
      "Input:  tensor([41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,  1,\n",
      "        10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33, 46,\n",
      "        37, 43, 49, 47])\n",
      "Target:  tensor([53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,  1, 10,\n",
      "        10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33, 46, 37,\n",
      "        43, 49, 47,  1])\n",
      "Input decoded:  MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS\n",
      "Target decoded:  YSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS \n",
      "Sequence:  5\n",
      "Input:  tensor([53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,  1, 10,\n",
      "        10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33, 46, 37,\n",
      "        43, 49, 47,  1])\n",
      "Target:  tensor([47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,  1, 10, 10,\n",
      "        10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43,\n",
      "        49, 47,  1, 37])\n",
      "Input decoded:  YSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS \n",
      "Target decoded:  STERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/f3fqnbfs4vg005y3fj658pd40000gn/T/ipykernel_7075/4240554814.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "text_chunks = [\n",
    "    text_encoded[i:i+chunk_size] for i in range(len(text_encoded)-chunk_size+1)\n",
    "]\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self,text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(),text_chunk[1:].long()\n",
    "\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))\n",
    "\n",
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(\"Sequence: \", i)\n",
    "    print(\"Input: \", seq)\n",
    "    print(\"Target: \", target)\n",
    "    print(\"Input decoded: \", \"\".join(char_array[seq]))\n",
    "    print(\"Target decoded: \", \"\".join(char_array[target]))\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset,batch_size=batch_size,shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(85, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size,vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self,x,hidden, cell):\n",
    "        out =  self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.fc(out).reshape(out.size(0),-1)\n",
    "        return out, hidden,cell\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden =torch.zeros(1,batch_size,self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1,batch_size,self.rnn_hidden_size)\n",
    "        return  hidden, cell\n",
    "    \n",
    "\n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size,embed_dim,rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 4.4364269256591795\n",
      "Epoch 500 Loss 1.3617974281311036\n",
      "Epoch 1000 Loss 1.2456331253051758\n",
      "Epoch 1500 Loss 1.233212947845459\n",
      "Epoch 2000 Loss 1.2209564208984376\n",
      "Epoch 2500 Loss 1.1708856582641602\n",
      "Epoch 3000 Loss 1.2241089820861817\n",
      "Epoch 3500 Loss 1.1715151786804199\n",
      "Epoch 4000 Loss 1.1603304862976074\n",
      "Epoch 4500 Loss 1.1339111328125\n",
      "Epoch 5000 Loss 1.131721591949463\n",
      "Epoch 5500 Loss 1.152293872833252\n",
      "Epoch 6000 Loss 1.1495393753051757\n",
      "Epoch 6500 Loss 1.104940700531006\n",
      "Epoch 7000 Loss 1.161044216156006\n",
      "Epoch 7500 Loss 1.187358570098877\n",
      "Epoch 8000 Loss 1.1354199409484864\n",
      "Epoch 8500 Loss 1.1028923034667968\n",
      "Epoch 9000 Loss 1.1335047721862792\n",
      "Epoch 9500 Loss 1.1468483924865722\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0.0\n",
    "    for c in range(seq_length):\n",
    "        output, hidden, cell = model(seq_batch[:,c],hidden,cell)\n",
    "        loss += loss_fn(output,target_batch[:,c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch} Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "def sample(model, starting_str, len_generated_text=500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor([[char2int[ch] for ch in starting_str]])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "    generated_str = starting_str\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(\n",
    "        encoded_input[:, c].view(1), hidden, cell\n",
    "        )\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(\n",
    "        last_char.view(1), hidden, cell\n",
    "        )\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "\n",
    "    return generated_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island is singular enough a difficulty.\n",
      "Cyrus Harding, as may derivain, and,\n",
      "the light dured a molluscer from theim, disputing out obtain,\n",
      "and the lad, viecial times of December,\n",
      "sweal of vessity, the two hung\n",
      "on them.”\n",
      "\n",
      "“Ah it even eight o’clock,” replied the reporter, whose scriences were to be doubled along the wood. Two her titude one of the sea as we to near him, as he\n",
      "would see, which appeared under which their sticks, and it was in wild exceed firm, and you tell now?”\n",
      "\n",
      "“And later, that everythi\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, \"The island\", 500, scale_factor=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"rnn_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
